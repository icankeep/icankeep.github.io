# 知识点复习
- Spring源码深度解析
    - 加载bean步骤
    - 几个bean循环依赖如何解决
- Redis
    - 哨兵
    - 集群
    - 数据类型(string,hash,set,list,zset)
    - 跳表实现
    - 分布式锁
        - Redis实现分布式锁(查看Redissson底层实现)
        - Zookeeper实现分布式锁
    - 主从复制
- 网络
    - [三次握手](#三次握手)
    - [四次挥手](#四次挥手)
    - [七层、四层、五层模型](https://www.cnblogs.com/wxd0108/p/7597216.html)
    - [拥塞控制](https://blog.csdn.net/coderDogg/article/details/88338858)
        - 慢开始(拥塞窗口从1开始，指数增长，直到增长到ssthresh，开始使用拥塞避免)
        - 拥塞避免(线性增长)
        - 快重传
        - 快恢复
    - 滑动窗口
    - [tcp、udp区别](#tcp、udp区别)
    - [http、https区别](#客户端使用https通信流程)
- 数据库
    - SQL语句
        - JOIN、LEFT JOIN、RIGHT JOIN、INNER JOIN
        - UNION、UNION ALL（UNION排序去重，UNION ALL则不会）
    - [存储引擎](https://icankeep.github.io/posts/2019/03/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/)
    - [索引](https://icankeep.github.io/posts/2019/03/MySQL%E4%B8%AD%E7%B4%A2%E5%BC%95/)
        - [B树和B+树的区别](#B树和B+树的区别)
        - [为什么数据库底层用B+树不用红黑树](#为什么数据库底层用B+树不用红黑树)
    - [锁及事务](https://icankeep.github.io/posts/2019/03/MySQL%E9%94%81%E6%9C%BA%E5%88%B6/)
    - 优化、分析慢查询，explain命令和trace命令
- 虚拟机
    - [内存分布](#内存分布)
    - [垃圾收集](#垃圾收集)
    - 判断对象死亡
        - 引用计数法（当对象相互引用时无法回收）
        - 可达性分析算法（从GC Root对象处用深度优先算法）
    - [四种引用类型](#四种引用类型)
    - [对象的逃生机会](#对象的逃生机会)
    - [频繁FullGc分析步骤](#频繁FullGc分析步骤)
    - 分析虚拟机工具、命令(Visual vm，JMC：Java Mission Control，JFR：Java Flight Recorder，jmap，jstack等)
    - [不影响虚拟机性能情况分析内存？](#不影响虚拟机性能情况分析内存？)
    - [双亲委派模型](#双亲委派模型)
- [Java基础](#java.util包下)
    - 并发包
    - 集合包
    - 自定义对象使用HashMap，HashSet需要重写hashCode和equals方法
    - 如何解决hash冲突
        - 开放定址法
        - 链地址法
        - 再散列法
- 基础框架
    - Spring
    - Spring Boot
    - Spring MVC
    - MyBatis
- 基础算法
    - [排序](https://github.com/icankeep/icankeep.github.io/blob/master/_posts/2019-04-29-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95.md)（平均时间复杂度，最坏时间复杂度，空间复杂度）
        - 快速排序（三向切分快速排序在数据重复情况较多的时候效率远高于双向切分）
        - 归并排序
        - 插入排序（希尔排序）
        - 堆排序
    - 搜索
        - 二分查找
        - 深度优先搜索
        - 广度优先搜索
    - 数据结构
- 设计模式
    - 单例模式
        - 双重检查锁定实现
        - 枚举类实现
        - 静态内部类实现
    - [代理模式](#代理)
        - 什么是代理
        - 动态代理和静态代理区别
        - JDK动态代理和CGLIB动态代理
    - 工厂方法模式
    - 模板方法模式
    - 享元模式（池技术，Integer缓存池-128至127，线程池，字符串常量池，数据库连接池）
        - 享元模式：运用共享技术有效地支持大量细粒度对象的复用。享元模式是一种结构型设计模式，当一个系统中出现了大量相同或者相似的细粒度对象的时候。细粒度就是小对象，属性少方法少的对象。就可以可以考虑使用享元模式来就行系统的设计。享元模式就是通过共享这些细小的对象进行重用，像Java中的string字符的不变性其实就是享元模式的应用！并且享元模式的两个核心点就是享元池，和享元工厂。
- 操作系统
    - [死锁](#死锁)
        - 导致死锁的4个必要条件
        - 死锁预防策略
        - 死锁避免策略
        - 死锁检测
        - 死锁解除
- 分布式
    - 一致性哈希算法
        - 一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0 - (2^32)-1（即哈希值是一个32位无符号整形）,数据会映射到顺时针方向最近的一台机器
        - 宕机、恢复、增加节点
        - 虚拟节点
    - CAP
        - Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者只可取其二，不可得兼。
    - BASE理论
        - Basically Available(基本可用)，Soft state（软状态）,和 Eventually consistent（最终一致性）
    - 分布式系统时钟
    - Zookeeper
    - Spring Cloud
- 虚拟化
    - Linux
    - Docker

## 三次握手
 TCP建立连接要进行3次握手
1. 主机A通过向主机B 发送一个含有同步序列号(SYN)的标志位的数据段给主机B ,向主机B 请求建立连接,通过这个数据段,主机A告诉主机B 两件事:我想要和你通信;你可以用哪个序列号作为起始数据段来回应我
1. 主机B 收到主机A的请求后,用一个带有确认应答(ACK)和同步序列号(SYN)标志位的数据段响应主机A,也告诉主机A两件事:我已经收到你的请求了,你可以传输数据了;你要用序列号作为起始数据段来回应我
1. 主机A收到这个数据段后,再发送一个确认应答(ACK),确认已收到主机B 的数据段:"我已收到回复,我现在要开始传输实际数据了

 名词解释
1. ACK  TCP报头的控制位之一,对数据进行确认.确认由目的端发出,用它来告诉发送端这个序列号之前的数据段都收到了.比如,确认号为X,则表示前X-1个数据段都收到了,只有当ACK=1时,确认号才有效,当ACK=0时,确认号无效,这时会要求重传数据,保证数据的完整性
1. SYN  同步序列号,TCP建立连接时将这个位置1
1. FIN  发送端完成发送任务位,当TCP完成数据传输需要断开时,提出断开连接的一方将这位置1

## 四次挥手
1. 当主机A完成数据传输后,将控制位FIN置1,提出停止TCP连接的请求
1. 主机B收到FIN后对其作出响应,确认这一方向上的TCP连接将关闭,将ACK置1
1. 由B端再提出反方向的关闭请求,将FIN置1
1. 主机A对主机B的请求进行确认,将ACK置1,双方向的关闭结束.
由TCP的三次握手和四次断开可以看出,TCP使用面向连接的通信方式,大大提高了数据通信的可靠性,使发送数据端
和接收端在数据正式传输前就有了交互,为数据正式传输打下了可靠的基础

## tcp、udp区别
TCP（Transmission Control Protocol，传输控制协议）是面向连接的协议，也就是说，在收发数据前，必须和对方建立可靠的连接。一个TCP连接必须要经过三次“对话”才能建立，其中的过程非常复杂，过程：主机A向主机B发出连接请求数据包：“我想给你发数据，可以吗？”，这是第一次对话；主机B向主机A发送同意连接和要求同步（同步就是两台主机一个在发送，一个在接收，协调工作）的数据包：“可以，你什么时候发？”，这是第二次对话；主机A再发出一个数据包确认主机B的要求同步：“我现在就发，你接着吧！”，这是第三次对话。三次“对话”的目的是使数据包的发送和接收同步，经过三次“对话”之后，主机A才向主机B正式发送数据。
   
区别
1. 基于连接与无连接；
1. 对系统资源的要求（TCP较多，UDP少）；
1. UDP程序结构较简单；
1. 流模式与数据报模式 ；
1. TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证。

## http、https区别
简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。
1. https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
1. http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
1. http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
1. http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

## 客户端使用https通信流程
客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤
1. 客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。
1. Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。
1. 客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。
1. 客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。
1. Web服务器利用自己的私钥解密出会话密钥。
1. Web服务器利用会话密钥加密与客户端之间的通信。

## B树和B+树的区别
1. 关键字集合分布在整颗树中；
1. 任何一个关键字出现且只出现在一个结点中；
1. 搜索有可能在非叶子结点结束；
1. 其搜索性能等价于在关键字全集内做一次二分查找；

b+树，是b树的一种变体，查询性能更好。m阶的b+树的特征：
1. 有n棵子树的非叶子结点中含有n个关键字（b树是n-1个），这些关键字不保存数据，只用来索引，所有数据都保存在叶子节点（b树是每个关键字都保存数据）。
1. 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
1. 所有的非叶子结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
1. 通常在b+树上有两个头指针，一个指向根结点，一个指向关键字最小的叶子结点。
1. 同一个数字会在不同节点中重复出现，根节点的最大元素就是b+树的最大元素。

b+树相比于b树的查询优势：
1. b+树的中间节点不保存数据，所以磁盘页能容纳更多节点元素，更“矮胖”；
1. b+树查询必须查找到叶子节点，b树只要匹配到即可不用管元素位置，因此b+树查找更稳定（并不慢）；
1. 对于范围查找来说，b+树只需遍历叶子节点链表即可，b树却需要重复地中序遍历；

## 为什么数据库底层用B+树不用红黑树
AVL 树（平衡二叉树）和红黑树（二叉查找树）基本都是存储在内存中才会使用的数据结构。在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁，进而导致效率低下的情况。操作系统读写磁盘的基本单位是扇区，而文件系统的基本单位是簇(Cluster)。也就是说，磁盘读写有一个最少内容的限制，即使我们只需要这个簇上的一个字节的内容，我们也要含着泪把一整个簇上的内容读完。那么，现在问题就来了，一个父节点只有 2 个子节点，并不能填满一个簇上的所有内容啊？那多余的内容岂不是要浪费了？我们怎么才能把浪费的这部分内容利用起来呢？哈哈，答案就是 B+ 树。由于 B+ 树分支比二叉树更多，所以相同数量的内容，B+ 树的深度更浅，深度代表什么？代表磁盘 io 次数啊！数据库设计的时候 B+ 树有多少个分支都是按照磁盘一个簇上最多能放多少节点设计的啊！所以，涉及到磁盘上查询的数据结构，一般都用 B+ 树啦

简单来说：红黑树最多只有两个子节点，而文件系统操作文件的基本单位是簇，因为IO操作比较耗时，IO次数取决于树的高度，所以为了提高一次IO的利用率，需要选择多路的B+树，否则会导致访问数据频繁IO，造成效率低下

## 内存分布
1. 程序计数器：线程私有。当前线程所执行的字节码的行号指示器。如果线程执行的是Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果是Native方法，这个计数器值则为空。
1. 虚拟机栈：线程私有。每个方法在执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接，方法出口等信息。每一个方法从调用直至执行完成就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。
1. 本地方法栈：与虚拟机栈作用相似。为Native方法服务。
1. 堆：所有的对象实例以及数组都要在堆上分配（栈上分配，所以对象在堆上分配并不一定）。细分为新生代，老年代。新生代分为Eden区和Survivor区，比例是8:1。-Xmx -Xms分别指定堆最大内存和堆初始内存。-Xmn指定堆新生代大小，-Xmn指定每个线程的堆栈大小
1. 方法区：也叫Non-Heap,用于存储已被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据

    [优秀博文](https://yq.aliyun.com/articles/94557?t=t1)
## 垃圾收集
1. 垃圾回收算法
    - 标记-清除算法：它的不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片。
    - 复制算法：新生代分为一块Eden区和两块Survivor区，每次收集将一块Eden和Survivor区中的存活对象将移到另一块Survivor区，当Survivor内存不够存放剩余对象时，需要老年代分配担保。
    - 标记-整理算法：存活的对象都向一端移动，然后直接清理掉端边界以外的内存。
1. 垃圾收集器
    - 新生代(复制算法)
        - Serial：单线程，在单个CPU的环境下，由于没有线程交互的开销，专心做垃圾收集可以获得最高的单线程收集效率。
        - ParNew：多线程版本的Serial。
        - Parallel Scavenge：注重吞吐量，可以使用参数控制最大垃圾收集时间和吞吐量的大小。可以使用参数开启自适应调节策略。
    - 老年代
        - CMS：标记-清理算法，初始标记->并发标记->重新标记->并发清除。注重停顿时间。CMS收集器对CPU资源非常敏感；CMS无法处理浮动垃圾；会产生空间碎片；
        - Serial Old：标记-整理算法
        - Parallel Old：标记-整理算法
    - G1收集器：将堆划分成对个Region，新生代和老年代不再是物理隔离的了，从整体上看采用标记-整理算法，从局部两个Region是采用复制算法。初始标记->并发标记->最终标记->筛选回收。可预测停顿时间的模型，在后台维护了一个优先列表，每次根据允许的收集时间，优先回收价值最大（回收所获得的空间大小以及回收所需时间的经验值）的Region。使用Remembered Set避免全堆扫描。
1. 垃圾收集产生碎片处理策略
可以在设置多次FullGc后采用一次带压缩的碎片整理

- 对象优先在Eden分配
- 大对象直接进入老年代
- 长期存活的对象将进入老年代
- 动态对象年龄判断
- 空间分配担保

## 四种引用类型
- 强引用
- 软引用
- 弱引用
- 虚引用

## 对象的逃生机会
1. 如果发现对象没有与GC Roots相连接的引用链，被第一次标记
1. 判断对象有没有必要执行finalize方法，如果对象没有覆盖finalize方法或者finalize方法已被调用过了，则没有必要执行
1. 否则将对象放置在F-Queue的队列之中，并在稍后由一个由虚拟机自动创建的低优先级的Finalizer线程去执行，并不保证一定执行结束
1. 如果对象在finalize方法中重新与引用链任何一个对象建立关联，则在第二次标记时它将被移出即将回收的集合

## 频繁FullGc分析步骤
1. 最大堆内存是否和初始堆内存大小是否一致
1. 堆内存大小和老年代大小是否合理
1. 垃圾回收算法是否合理
1. 是否有不合理大对象
1. 是否有未关闭的连接或者未释放的资源
1. 对象不需要使用了就及时赋值null

## 不影响虚拟机性能情况分析线上问题？
使用Linux命令
- top：查看cpu和内存使用情况
- netstat：查看端口使用情况

使用VisualVm等工具dump等影响虚拟机性能
## 双亲委派模型
- 模型：启动类加载器<-扩展类加载器<-应用程序类加载器<-自定义类加载器
- 概念：一个类加载器收到了类加载的请求，它首先将这个请求委派给父类加载器去完成，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围没有找到所需的类）时，子加载器才会尝试自己去加载。
- 好处：保证Java程序稳定运作，底层不会轻易被用户自定义类破坏。自定义Object类可以被编译，无法加载运行
- 被破坏：jdk1.2之前没有引入双亲委派模型，用户通过继承ClassLoader重写loadClass方法自定义类加载器

## 代理
1. 什么是代理
    为其他对象提供一种代理，以控制对这个对象的访问。代理对象在客户端和目标对象之间起到中介的作用，其特征是代理类和委托类实现相同的接口。可以在对象执行指定方法前加入初始化工作和结束方法时加入扫尾工作。
1. 动态代理和静态代理区别
    静态代理是由程序员创建或特定工具自动生成源代码，在对其编译，在程序员运行之前，代理类字节码文件就已经被创建了。动态代理是在程序运行时通过反射机制动态创建的。
1. JDK动态代理和CGLIB动态代理

## 死锁
### 导致死锁的4个必要条件
1、互斥。一次只有一个进程可以使用一个资源。其他进程不能访问已分配给其他进程的资源。
2、占有且等待。当一个进程等待其他进程时，继续占有已经分配的资源。
3、不可抢占。不能强行抢占进程已占有的资源。
4、循环等待。存在一个封闭的进程链，使得每个进程至少占有此链中下一个进程所需要的一个资源。

### 死锁预防策略
1. 打破互斥条件：允许进程同时访问资源（有些资源就是不可以同时访问的，无实用价值）
1. 打破占有且等待条件：实行资源预分配策略，即进程在运行前一次性的向系统申请它所需要的全部资源(不可预测资源的使用，利用率低，降低并发性)
1. 打破不可抢占条件：比如给进程设置优先级，高优先级的可以抢占资源(实现困难，降低系统性能)
1. 破坏循环等待条件：采用这种策略，即把资源事先分类编号，按号分配，使进程在申请，占用资源时不会形成环路。所有进程对资源的请求必须严格按资源序号递增的顺序提出（限制和编号实现困难，增加系统开销，有些资源暂时不用也需要先申请，增加了进程对资源的占用时间）

### 死锁避免策略
银行家算法：首先需要定义状态和安全状态的概念。系统的状态是当前给进程分配的资源情况。因此，状态包含两个向量Resource（系统中每种资源的总量）和Available（未分配给进程的每种资源的总量）及两个矩阵Claim（表示进程对资源的需求）和Allocation（表示当前分配给进程的资源）。安全状态是指至少有一个资源分配序列不会导致死锁。当进程请求一组资源时，假设同意该请求，从而改变了系统的状态，然后确定其结果是否还处于安全状态。如果是，同意这个请求；如果不是，阻塞该进程知道同意该请求后系统状态仍然是安全的。

### 死锁检测
资源分配图&&死锁定理

### 死锁解除
1. 资源剥夺法。挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源时，而处于资源匮乏的状态。
1. 进程撤销法。强制撤销一个或一部分进程并剥夺这些进程的资源。撤销的原则可以按进程的优先级和撤销进程代价的高低进行。
1. 进程回退法。让一个或多个进程回退到足以回避死锁的地步，进程回退时资源释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

[顶部](#知识点复习)
## java.util包下
1. WeakHashMap
    - 新建WeakHashMap，将“键值对”添加到WeakHashMap中。实际上，WeakHashMap是通过数组table保存Entry(键值对)；每一个Entry实际上是一个单向链表，即Entry是键值对链表。
    - 当某“弱键”不再被其它对象引用，并被GC回收时。在GC回收该“弱键”时，这个“弱键”也同时会被添加到ReferenceQueue(queue)队列中。
    - 当下一次我们需要操作WeakHashMap时，会先同步table和queue。table中保存了全部的键值对，而queue中保存被GC回收的键值对；同步它们，就是删除table中被GC回收的键值对。这就是“弱键”如何被自动从WeakHashMap中删除的步骤了。和HashMap一样，WeakHashMap是不同步的。可以使用 Collections.synchronizedMap 方法来构造同步的 WeakHashMap，既然有WeakHashMap，那么有WeakHashSet吗？  java collections包是没有直接提供WeakHashSet的。我们可以通过Collections.newSetFromMap(Map<E,Boolean> map)方法可以将任何 Map包装成一个Set。
1. Vector和ArrayList
    1. Vector是线程安全的，在数据元素操作方法上都添加了Synchronize修饰
    1. 如果不传递参数，Vector默认大小为10，且立即创建长度为10的数组，ArrayList会等待到添加元素才创建长度为10的数组
    1. Vector扩容可指定扩容大小，如果未指定默认为两倍，ArrayList为1.5倍
1. ArrayList扩容
    1. add（E e）：添加元素，首先会判断 elementData 数组的长度，然后设置值
    1. ensureCapacityInternal（int minCapacity）：判断 element 是否为空，如果是，则设置默认数组长度
    1. ensureExplicitCapacity（int minCapacity）：判断预期增长数组长度是否超过当前容量，如果过超过，则调用grow（）
    1. grow(int minCapacity)：对数组进行扩展
    1. 如果newCapacity大于MAX_ARRAY_SIZE则newCapacity=Integer.MAX_VALUE
1. ArrayList和LinkedList
    1. ArrayList底层数组实现，LinkedList底层链表实现
    1. ArrayList可按索引值查询数据，效率高。LinkedList插入和删除元素效率高
1. UUID
    - 根据时间和机器mac地址生成随机数
1. TreeMap、TreeSet
    - 底层红黑树实现
1. TimSort
1. Stack、ArrayDeque、LinkedList
1. PriorityQueue重写比较器
1. LinkedHashMap、LinkedHashSet
    - 可以重写removeEldestEntry创建一个最近最频繁使用的缓存器，LeetCode
    ```java
    Map<T, T> map = new LinkedHashMap<>(int initialCapacity,float loadFactor,boolean accessOrder){
        protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {
            return size() > initialCapacity;
        }
    };
    ```
1. [IdentityHashMap](https://blog.csdn.net/f641385712/article/details/81880711)
    - 比如对于要保存的key，k1和k2，当且仅当k1== k2的时候，IdentityHashMap才会相等，而对于HashMap来说，相等的条件则是：对比两个key的hashCode相等
    - IdentityHashMap不是Map的通用实现，它有意违反了Map的常规协定。并且IdentityHashMap允许key和value都为null。
    - 同HashMap，IdentityHashMap也是无序的，并且该类不是线程安全的，如果要使之线程安全，可以调用Collections.synchronizedMap(new IdentityHashMap(…))方法来实现。
1. Hashtable和HashMap
    - Hashtable是线程安全的。在数据操作的方法上都添加了Synchronize方法
    - 继承的父类不一样。Hashtable继承Dictionary类，HashMap继承AbstractMap类
    - Hashtable比HashMap多提供了elments() 和contains() 两个方法。
    - Hashtable既不支持Null key也不支持Null value。HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null。
    - 计算hash值的方法不同
    - 初始容量大小和每次扩充容量大小的不同，Hashtable默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。
    - 都实现了相同的接口。Map<K,V>, Cloneable, Serializable
1. HashMap的扩容
    - 调用resize方法，每次扩容2倍
1. HashMap在并发插入情况下会遇到的问题
    - 产生环造成死循环

## java.util.concurrent.atomic包下
1. AtomicInteger、AtomicLong、AtomicReference、AtomicBoolean
    AtomicInterger、AtomicLong底层实现sun.misc.Unsafe，AtomicBoolean将值转为int值再进行操作
1. AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray
    相比较于上面三个，多传了一个索引值参数
1. AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater
    修改某个对象中的某个字段
1. AtomicStampedReference
    - 通过volatile和Unsafe提供的CAS函数实现原子操作。 自旋+CAS的无锁操作保证共享变量的线程安全
    - value是volatile类型，这保证了：当某线程修改value的值时，其他线程看到的value的值都是最新的值，即修改之后的volatile的值
    - 通过CAS设置value。这保证了：某线程池通过CAS函数（如compareAndSet函数）设置value时，它的操作时原子性的，即线程在操作vu略时不会被中断。
    - 但是CAS操作可能存在ABA问题。AtomicStampedReference的出现就是为了解决这问题
    - 内部添加了Pair静态内部类，封装了reference和时间戳，CAS设置值时除了比较reference还要比较时间戳是否和预期的相同
1. AtomicMarkableReference
    - 和AtomicStampedReference差不多，Pair封装了reference和boolean mark值，只有当reference、mark满足预期才会修改

## java.util.concurrent.lock包下
1. AbstractQueuedSynchronizer、AbstractQueuedLongSynchronizer、AbstractOwnableSynchronizer
1. Condition
1. Lock、ReentrantLock、ReadWriteLock、ReentrantReadWriteLock
1. StampedLock
    StampedLock的主要特点概括一下，有以下几点：
    1. 所有获取锁的方法，都返回一个邮戳（Stamp），Stamp为0表示获取失败，其余都表示成功；
    1. 所有释放锁的方法，都需要一个邮戳（Stamp），这个Stamp必须是和成功获取锁时得到的Stamp一致；
    1. StampedLock是不可重入的；（如果一个线程已经持有了写锁，再去获取写锁的话就会造成死锁）
    1. StampedLock有三种访问模式：
        - Reading（读模式）：功能和ReentrantReadWriteLock的读锁类似
        - Writing（写模式）：功能和ReentrantReadWriteLock的写锁类似
        - Optimistic reading（乐观读模式）：这是一种优化的读模式。
        StampedLock支持读锁和写锁的相互转换
    1. 我们知道RRW中，当线程获取到写锁后，可以降级为读锁，但是读锁是不能直接升级为写锁的。
    1. StampedLock提供了读锁和写锁相互转换的功能，使得该类支持更多的应用场景。
    1. 无论写锁还是读锁，都不支持Conditon等待
    > 我们知道，在ReentrantReadWriteLock中，当读锁被使用时，如果有线程尝试获取写锁，该写线程会阻塞。
    > 但是，在Optimistic reading中，即使读线程获取到了读锁，写线程尝试获取写锁也不会阻塞，这相当于对读模式的优化，但是可能会导致数据不一致的问题。所以，当使用Optimistic reading获取到读锁时，> 必须对获取结果进行校验。
1. LockSupport
    Lock工具类，提供park,unpark,parkNanos,parkUtil等方法

## java.util.concurrent包下
Excutor --> ExcutorService --> AbstractExecutorService --> ForkJoinPool
1. ArrayBlockingQueue、DelayQueue、SynchronousQueue、LinkedBlockingQueue、LinkedBlockingDeque、LinkedTransferQueue、PriorityBlockingQueue
1. CopyOnWriteArrayList、CopyOnWriteArraySet
    1. 实现了List接口
    1. 内部持有一个ReentrantLock lock = new ReentrantLock();
    1. 底层是用volatile transient声明的数组 array
    1. 读写分离，写时复制出一个新的数组,长度加1，完成插入、修改或者移除操作后将新数组赋值给array
    1. 我知道Vector是增删改查方法都加了synchronized，保证同步，但是每个方法执行的时候都要去获得锁，性能就会大大下降，而CopyOnWriteArrayList 只是在增删改上加锁，但是读不加锁，在读方面的性能就好于Vector，CopyOnWriteArrayList支持读多写少的并发情况。
1. ConcurrentSkipListMap、ConcurrentSkipListSet
    跳表（SkipList）是一种随机化的数据结构，通过“空间来换取时间”的一个算法，建立多级索引，实现以二分查找遍历一个有序链表。时间复杂度等同于红黑树，O(log n)。但实现却远远比红黑树要简单
1. Callable和Runnable
    - Callable接口重写call方法，可以带结果返回值
    - Runnable接口重写run方法，不带返回值
1. ConcurrentHashMap和HashMap
1. CountDownLatch、CyclicBarrier、Semaphore
    - CountDownLatch强调的是多个点都到达了就不阻塞，CylicBarrier强调的是等待多个线程都到达了再一起释放。
    - CountDownLatch只可以使用一次，CylicBarrier可以使用reset函数重置之循环使用。
1. ThreadPoolExecutor
    ```java
    public ThreadPoolExecutor(int corePoolSize,
                                int maximumPoolSize,
                                long keepAliveTime,
                                TimeUnit unit,
                                BlockingQueue<Runnable> workQueue,
                                ThreadFactory threadFactory,
                                RejectedExecutionHandler handler)
    ```
    - corePoolSize指核心线程数，当线程池线程数小于该值，加入任务时没有空闲线程都会新创建线程
    - maximumPoolSize当线程池线程达到核心线程数，且小于maximumPoolSize，且workQueue中任务已满，则会新创建线程执行任务
    - keepAliveTime空闲线程存活时间
    - RejectedExecutionHandler 当线程数已达最大线程数，且workQueue已满，则会处理handler指定的策略
1. Exchanger  
    实现线程间变量交换
1. Excutors
    - 包装Runnable对象为Callable
    - newFixedThreadPool、newCachedThreadPool、newScheduledThreadPool、newSingleThreadExecutor
1. ForkJoin
    - 任务分片处理框架
1. Future
    - 任务接口，可以异步执行

 ForkJoin Future

## java.lang包下
1. Object
- 浅拷贝：被复制对象的所有值属性都含有与原来对象的相同，而所有的对象引用属性仍然指向原来的对象。
- 深拷贝：在浅拷贝的基础上，所有引用其他对象的变量也进行了clone，并指向被复制过的新对象。
- 也就是说，一个默认的clone()方法实现机制，仍然是赋值。如果一个被复制的属性都是基本类型，那么只需要实现当前类的cloneable机制就可以了，此为浅拷贝。如果被复制对象的属性包含其他实体类对象引用，那么这些实体类对象都需要实现cloneable接口并覆盖clone()方法。